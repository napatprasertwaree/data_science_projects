{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d0a3035d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from surprise import SVD, Reader\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fafd8a",
   "metadata": {},
   "source": [
    "# TL;DR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a5cb75",
   "metadata": {},
   "source": [
    "- Implement an algorithm for predicting rating, based on matrix factorization\n",
    "- Comparing with varioud model. We could see that while our model may not be perfect, class MatrixFactorization, it demonstrates respectable performance in accurately predicting ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b96564e",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9322b512",
   "metadata": {},
   "source": [
    "There are numerous methods available for making suggestions based on data. In this report, we will be implementing an algorithm aimed at predicting ratings. Specifically, we'll utilize matrix factorization to accomplish this task. Furthermore, we'll conduct a comparative analysis with other models to evaluate the effectiveness of our approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5b6e79",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219be487",
   "metadata": {},
   "source": [
    "For matrix factorization, it's crucial to have dense data for effective analysis. However, encountering missing data is inevitable, as it represents the very information we aim to predict. Minimizing both Root Mean Square Error (RMSE) and Mean Absolute Error (MAE) is essential for enhancing predictive accuracy. To address this, we will employ Stochastic Gradient Descent (SGD) to fill in these missing values, optimizing our model's performance. Furthermore, determining the appropriate number of factors is vital for obtaining meaningful results. Therefore, part of our analysis will involve fine-tuning the number of factors to ensure optimal outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e7874bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorization(surprise.AlgoBase):\n",
    "    '''A basic rating prediction algorithm based on matrix factorization.'''\n",
    "    \n",
    "    def __init__(self, learning_rate, n_epochs, n_factors):\n",
    "        \n",
    "        self.lr = learning_rate  # learning rate for SGD\n",
    "        self.n_epochs = n_epochs  # number of iterations of SGD\n",
    "        self.n_factors = n_factors  # number of factors\n",
    "        \n",
    "    def fit(self, trainset):\n",
    "        '''Learn the vectors p_u and q_i with SGD'''\n",
    "        \n",
    "        print('Start fitting the data')\n",
    "        \n",
    "        # Randomly initialize the user and item factors.\n",
    "        p = np.random.normal(0, .1, (trainset.n_users, self.n_factors))\n",
    "        q = np.random.normal(0, .1, (trainset.n_items, self.n_factors))\n",
    "        \n",
    "        # SGD procedure\n",
    "        for _ in range(self.n_epochs):\n",
    "            for u, i, r_ui in trainset.all_ratings():\n",
    "                err = r_ui - np.dot(p[u], q[i])\n",
    "                # Update vectors p_u and q_i\n",
    "                p[u] += self.lr * err * q[i]\n",
    "                q[i] += self.lr * err * p[u]\n",
    "        \n",
    "        self.p, self.q = p, q\n",
    "        self.trainset = trainset\n",
    "\n",
    "    def estimate(self, u, i):\n",
    "        '''Return the estmimated rating of user u for item i.'''\n",
    "        \n",
    "        if self.trainset.knows_user(u) and self.trainset.knows_item(i):\n",
    "            return np.dot(self.p[u], self.q[i])\n",
    "        else:\n",
    "            return self.trainset.global_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0abb3ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting data with SGD...\n",
      "Fitting data with SGD...\n",
      "Evaluating RMSE, MAE of algorithm MatrixFacto on 2 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Mean    Std     \n",
      "RMSE (testset)    0.9202  0.9238  0.9220  0.0018  \n",
      "MAE (testset)     0.7225  0.7259  0.7242  0.0017  \n",
      "Fit time          12.95   12.81   12.88   0.07    \n",
      "Test time         1.31    1.30    1.30    0.00    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.92024193, 0.92378354]),\n",
       " 'test_mae': array([0.72245294, 0.7258521 ]),\n",
       " 'fit_time': (12.950942277908325, 12.808483123779297),\n",
       " 'test_time': (1.3050119876861572, 1.302353858947754)}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader = Reader()\n",
    "\n",
    "ratingDf = pd.read_csv('~/Desktop/Work/movielens_recommendation/ratings.csv')\n",
    "\n",
    "ratingDf = ratingDf.iloc[:, :3]\n",
    "data = Dataset.load_from_df(ratingDf, reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "daf8c774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of factors is: 5\n",
      "Start fitting the data\n",
      "Start fitting the data\n",
      "Evaluating RMSE, MAE of algorithm MatrixFactorization on 2 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Mean    Std     \n",
      "RMSE (testset)    0.9172  0.9245  0.9208  0.0036  \n",
      "MAE (testset)     0.7221  0.7273  0.7247  0.0026  \n",
      "Fit time          12.71   13.07   12.89   0.18    \n",
      "Test time         1.14    1.19    1.17    0.02    \n",
      "number of factors is: 10\n",
      "Start fitting the data\n",
      "Start fitting the data\n",
      "Evaluating RMSE, MAE of algorithm MatrixFactorization on 2 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Mean    Std     \n",
      "RMSE (testset)    0.9198  0.9238  0.9218  0.0020  \n",
      "MAE (testset)     0.7223  0.7247  0.7235  0.0012  \n",
      "Fit time          13.01   12.95   12.98   0.03    \n",
      "Test time         1.31    1.23    1.27    0.04    \n",
      "number of factors is: 15\n",
      "Start fitting the data\n",
      "Start fitting the data\n",
      "Evaluating RMSE, MAE of algorithm MatrixFactorization on 2 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Mean    Std     \n",
      "RMSE (testset)    0.9232  0.9236  0.9234  0.0002  \n",
      "MAE (testset)     0.7240  0.7243  0.7241  0.0002  \n",
      "Fit time          12.94   13.06   13.00   0.06    \n",
      "Test time         1.03    1.32    1.18    0.14    \n",
      "number of factors is: 20\n",
      "Start fitting the data\n",
      "Start fitting the data\n",
      "Evaluating RMSE, MAE of algorithm MatrixFactorization on 2 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Mean    Std     \n",
      "RMSE (testset)    0.9298  0.9304  0.9301  0.0003  \n",
      "MAE (testset)     0.7293  0.7289  0.7291  0.0002  \n",
      "Fit time          12.86   13.34   13.10   0.24    \n",
      "Test time         1.21    1.24    1.23    0.02    \n",
      "number of factors is: 25\n",
      "Start fitting the data\n",
      "Start fitting the data\n",
      "Evaluating RMSE, MAE of algorithm MatrixFactorization on 2 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Mean    Std     \n",
      "RMSE (testset)    0.9319  0.9342  0.9330  0.0012  \n",
      "MAE (testset)     0.7305  0.7323  0.7314  0.0009  \n",
      "Fit time          13.03   13.06   13.04   0.02    \n",
      "Test time         1.06    1.33    1.19    0.14    \n"
     ]
    }
   ],
   "source": [
    "n_factors_range = [5, 10, 15, 20, 25]\n",
    "results = {}\n",
    "\n",
    "for n_factors in n_factors_range:\n",
    "\n",
    "    algo = MatrixFactorization(learning_rate=.01, n_epochs=10, n_factors=n_factors)\n",
    "    print('')\n",
    "    print(\"number of factors is:\", n_factors)\n",
    "    cvResults = cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=2, verbose=True)\n",
    "    \n",
    "    results[n_factors] = {\n",
    "        'RMSE': cvResults['test_rmse'],\n",
    "        'MAE': cvResults['test_mae'],\n",
    "        'fit_time': cvResults['fit_time'],\n",
    "        'test_time': cvResults['test_time']\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7167170a",
   "metadata": {},
   "source": [
    "Based on the results derived from our analysis, it is apparent that employing 5 factors yields the most optimal outcomes for our model. However, the question arises: with a Root Mean Square Error (RMSE) of 0.92 and a Mean Absolute Error (MAE) of 0.72, is this the pinnacle of our performance, or is there room for improvement?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "76c6676b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNBasic on 2 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Mean    Std     \n",
      "RMSE (testset)    0.9437  0.9421  0.9429  0.0008  \n",
      "MAE (testset)     0.7461  0.7439  0.7450  0.0011  \n",
      "Fit time          3.99    3.95    3.97    0.02    \n",
      "Test time         68.52   70.45   69.48   0.96    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.94373928, 0.94205207]),\n",
       " 'test_mae': array([0.74610588, 0.74393816]),\n",
       " 'fit_time': (3.991666078567505, 3.9493441581726074),\n",
       " 'test_time': (68.52197599411011, 70.44561815261841)}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = surprise.KNNBasic()\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=2, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a343a1dc",
   "metadata": {},
   "source": [
    "By employing KNNBasic, we achieved a Root Mean Square Error (RMSE) of 0.94 and a Mean Absolute Error (MAE) of 0.74. These metrics suggest that our model is performing quite satisfactorily, indicating that our approach is effective in generating accurate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b22368d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 2 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Mean    Std     \n",
      "RMSE (testset)    0.9022  0.9034  0.9028  0.0006  \n",
      "MAE (testset)     0.7105  0.7118  0.7112  0.0006  \n",
      "Fit time          2.88    3.00    2.94    0.06    \n",
      "Test time         1.29    1.26    1.27    0.01    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.90222826, 0.90337181]),\n",
       " 'test_mae': array([0.71054359, 0.71178012]),\n",
       " 'fit_time': (2.8758890628814697, 3.0029540061950684),\n",
       " 'test_time': (1.286635160446167, 1.2597870826721191)}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = surprise.SVD()\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=2, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718e65eb",
   "metadata": {},
   "source": [
    "Utilizing Singular Value Decomposition (SVD) from the Surprise library, we observed a Root Mean Square Error (RMSE) of 0.90 and a Mean Absolute Error (MAE) of 0.711. These results suggest that while our model may not be perfect, it demonstrates respectable performance in accurately predicting ratings."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
